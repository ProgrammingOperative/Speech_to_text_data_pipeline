{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_broker = \"localhost:9092\" #Yet to figure out how the endpoint links to spark\n",
    "bucket_prefix = \"my-company-bucket-prefix-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Locations\n",
    "\n",
    "To write the Delta table, we need 3 settings: the location of the delta table, the location of the checkpoints and the location of the schema file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_bucket = \"/mnt/10ac-batch-5/week9/g3\"\n",
    "bucket = \"/mnt/10ac-batch-5/week9/g3/speech-to-text-delta\"\n",
    "\n",
    "\n",
    "delta_location = bucket + \"/delta-table\"\n",
    "checkpoint_location = bucket + \"/checkpoints\"\n",
    "schema_location = bucket + \"/kafka_schema.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Schema\n",
    "- Assuming the streaming data from kafka is in json format. To properly read this data into spark, we have to provide a schema.\n",
    "- For efficiency, we will infer the schema one and save it to an s3 location so that every time we save data into the delta lake, we only have to infer rather than re-reading the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
